{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: we can't actually use pandas in our algorithm, but we can use it to read in our df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "binary recursive partitioning. This is an iterative process of splitting the data into partitions, and then splitting it up further on each of the branches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/decision-tree-classification-de64fc4d5aac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/what-is-a-decision-tree-22975f00f3e1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantifying splits with impurity\n",
    "https://victorzhou.com/blog/gini-impurity/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Gini Impurity is the probability of incorrectly classifying a randomly chosen element in the dataset if it were randomly labeled according to the class distribution in the dataset.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Classifier\n",
    "Using the decision algorithm, **we start at the tree root and split the data on the feature that results in the largest information gain (IG)** (reduction in uncertainty towards the final decision).\n",
    "In an iterative process, we can then repeat this splitting procedure at each child node **until the leaves are pure**. This means that the samples at each leaf node all belong to the same class.\n",
    "In practice, we may **set a limit on the depth of the tree** to prevent overfitting. We compromise on purity here somewhat as the final leaves may still have some impurity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='Id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, test_size):\n",
    "    \n",
    "    # get a list of indices\n",
    "    indices = df.index.to_list()\n",
    "    \n",
    "    # if a float result, rounding test_size to an int is needed\n",
    "    test_size = round(test_size * len(df))\n",
    "    \n",
    "    # get a random choice of the indices\n",
    "    test_indices = np.random.default_rng().choice(indices, size=test_size)\n",
    "\n",
    "    # create our test df\n",
    "    test = df.loc[test_indices]\n",
    "        \n",
    "    # create our train df \n",
    "    train = df.drop(test_indices)\n",
    "    \n",
    "    # return both\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if percentages work \n",
    "train, test = train_test_split(df, 0.20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((125, 5), (30, 5))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: array([4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 5.0, 5.1, 5.2, 5.3, 5.4, 5.5,\n",
      "       5.6, 5.7, 5.8, 5.9, 6.0, 6.1, 6.2, 6.3, 6.4, 6.5, 6.6, 6.7, 6.8,\n",
      "       6.9, 7.0, 7.1, 7.2, 7.3, 7.4, 7.7, 7.9], dtype=object)}\n",
      "{0: array([4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 5.0, 5.1, 5.2, 5.3, 5.4, 5.5,\n",
      "       5.6, 5.7, 5.8, 5.9, 6.0, 6.1, 6.2, 6.3, 6.4, 6.5, 6.6, 6.7, 6.8,\n",
      "       6.9, 7.0, 7.1, 7.2, 7.3, 7.4, 7.7, 7.9], dtype=object), 1: array([2.0, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9, 3.0, 3.1, 3.2, 3.3,\n",
      "       3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 4.1, 4.4], dtype=object)}\n",
      "{0: array([4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 5.0, 5.1, 5.2, 5.3, 5.4, 5.5,\n",
      "       5.6, 5.7, 5.8, 5.9, 6.0, 6.1, 6.2, 6.3, 6.4, 6.5, 6.6, 6.7, 6.8,\n",
      "       6.9, 7.0, 7.1, 7.2, 7.3, 7.4, 7.7, 7.9], dtype=object), 1: array([2.0, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9, 3.0, 3.1, 3.2, 3.3,\n",
      "       3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 4.1, 4.4], dtype=object), 2: array([1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.9, 3.0, 3.5, 3.6, 3.7,\n",
      "       3.8, 3.9, 4.0, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 5.0,\n",
      "       5.1, 5.2, 5.3, 5.4, 5.5, 5.6, 5.7, 5.8, 5.9, 6.0, 6.1, 6.3, 6.4,\n",
      "       6.7, 6.9], dtype=object)}\n",
      "{0: array([4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 5.0, 5.1, 5.2, 5.3, 5.4, 5.5,\n",
      "       5.6, 5.7, 5.8, 5.9, 6.0, 6.1, 6.2, 6.3, 6.4, 6.5, 6.6, 6.7, 6.8,\n",
      "       6.9, 7.0, 7.1, 7.2, 7.3, 7.4, 7.7, 7.9], dtype=object), 1: array([2.0, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9, 3.0, 3.1, 3.2, 3.3,\n",
      "       3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 4.1, 4.4], dtype=object), 2: array([1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.9, 3.0, 3.5, 3.6, 3.7,\n",
      "       3.8, 3.9, 4.0, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 5.0,\n",
      "       5.1, 5.2, 5.3, 5.4, 5.5, 5.6, 5.7, 5.8, 5.9, 6.0, 6.1, 6.3, 6.4,\n",
      "       6.7, 6.9], dtype=object), 3: array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6,\n",
      "       1.7, 1.8, 1.9, 2.0, 2.1, 2.2, 2.3, 2.4, 2.5], dtype=object)}\n"
     ]
    }
   ],
   "source": [
    "potential_splits = {}\n",
    "\n",
    "n_features = len(train_data[0]) - 1\n",
    "\n",
    "for feature in range(n_features):\n",
    "\n",
    "    potential_splits[feature] = np.unique(train_data[:, feature])\n",
    "    \n",
    "    print(potential_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2, 'Iris-setosa'],\n",
       "       [4.9, 3.0, 1.4, 0.2, 'Iris-setosa'],\n",
       "       [4.7, 3.2, 1.3, 0.2, 'Iris-setosa'],\n",
       "       [4.6, 3.1, 1.5, 0.2, 'Iris-setosa'],\n",
       "       [5.0, 3.6, 1.4, 0.2, 'Iris-setosa']], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy array \n",
    "train_data = train.values\n",
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purity(data):\n",
    "    \n",
    "    # get our labels for this data \n",
    "    labels = data[:,-1]\n",
    "    unique_classes = np.unique(labels)\n",
    "    \n",
    "    # see if we only have one label left\n",
    "    if len(unique_classes) == 1:\n",
    "        return True\n",
    "    else: \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [np.unique(labels)[2]] * len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(data):\n",
    "    \n",
    "    # get the true labels for the input data\n",
    "    labels = data[:,-1]\n",
    "    \n",
    "    # get the unique labels and label counts for this input data\n",
    "    classes, class_counts = np.unique(labels, return_counts=True)\n",
    "    \n",
    "    # get the majority class\n",
    "    index = class_counts.argmax()\n",
    "    \n",
    "    # classify our input as the majority\n",
    "    classification = classes[index]\n",
    "    \n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n",
    "\n",
    "    index = counts_unique_classes.argmax()\n",
    "    classification = unique_classes[index]\n",
    "    \n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = classify(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iris-virginica'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(train[train.PetalWidthCm > 1.2].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iris-virginica'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Counter(labels)\n",
    "c.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potential splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm         Species\n",
       "144            6.7           3.3            5.7           2.5  Iris-virginica\n",
       "145            6.7           3.0            5.2           2.3  Iris-virginica\n",
       "146            6.3           2.5            5.0           1.9  Iris-virginica\n",
       "147            6.5           3.0            5.2           2.0  Iris-virginica\n",
       "149            5.9           3.0            5.1           1.8  Iris-virginica"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential_splits(data):\n",
    "    \n",
    "    potential_splits = {}\n",
    "\n",
    "    # how many columns are there\n",
    "    _, n_columns = data.shape\n",
    "    \n",
    "    # for each column in our array \n",
    "    for column_index in range(n_columns - 1):\n",
    "    \n",
    "        # we want our key to be the column index\n",
    "        potential_splits[column_index] = []\n",
    "    \n",
    "        # we want our value to be each row value at that index\n",
    "        values = data[:, column_index]\n",
    "    \n",
    "        # we want all the possible splits\n",
    "        unique_values = np.unique(values)\n",
    "\n",
    "        # for each index in range(15)\n",
    "        for index in range(len(unique_values)):\n",
    "\n",
    "            if index != 0:\n",
    "\n",
    "                # get the sum of the current and previous values and \n",
    "                current_value = unique_values[index]\n",
    "                previous_value = unique_values[index-1]\n",
    "                potential_split = (current_value + previous_value) / 2\n",
    "\n",
    "                potential_splits[column_index].append(potential_split)\n",
    "    \n",
    "    return potential_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_splits = get_potential_splits(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one for each column besides the label\n",
    "potential_splits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 463.25x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lmplot(data=train, x='PetalWidthCm', y='PetalLengthCm', hue='Species', fit_reg=False)\n",
    "plt.hlines(y=potential_splits[2], xmin=0, xmax=2.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2, 'Iris-setosa'],\n",
       "       [4.9, 3.0, 1.4, 0.2, 'Iris-setosa'],\n",
       "       [4.7, 3.2, 1.3, 0.2, 'Iris-setosa'],\n",
       "       [4.6, 3.1, 1.5, 0.2, 'Iris-setosa'],\n",
       "       [5.0, 3.6, 1.4, 0.2, 'Iris-setosa']], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which question is most important?\n",
    "# ex. \"is the petal width less/larger than value\"\n",
    "# we have four questions to ask it\n",
    "\n",
    "# split dataset based on column and value\n",
    "def split_data(data, split_col, split_val):\n",
    "    \n",
    "    # get that specific column's values\n",
    "    split_column_values = data[:, split_col]\n",
    "    print(split_column_values.shape)\n",
    "    \n",
    "    # get the data below the specified value \n",
    "    data_below = data[split_column_values <= split_val]\n",
    "    \n",
    "    # get the data above the specified value\n",
    "    data_above = data[split_column_values > split_val]\n",
    "    \n",
    "    return data_below, data_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_col = 2\n",
    "split_val = 2.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125,)\n"
     ]
    }
   ],
   "source": [
    "# Question: is our petal width < or > 0.8?\n",
    "data_below, data_above = split_data(train_data, split_col, split_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to calculate entropy for a split:\n",
    "\n",
    "Calculate entropy of parent node\n",
    "Calculate entropy of each individual node of split and calculate weighted average of all sub-nodes available in split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "entropy = sum(probs * -log2(probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    " def calculate_entropy(data):\n",
    "        \n",
    "    labels = data[:,-1]\n",
    "    _, counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "    probs = counts / counts.sum()\n",
    "\n",
    "    entropy = sum(probs * -np.log2(probs))\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, counts = np.unique(labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([41, 39, 45])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "41\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "labels = train_data[:,-1]\n",
    "\n",
    "counter = Counter(labels)\n",
    "for c in counter.most_common():\n",
    "    print(c[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.array([c[1] for c in counter.most_common()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45, 41, 39])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = counts / len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36 , 0.328, 0.312])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overall_entropy(data_below, data_above):\n",
    "    \n",
    "    total_data_points = len(data_below) + len(data_above)\n",
    "    \n",
    "    # weight of data below\n",
    "    p_of_data_below = len(data_below) / total_data_points\n",
    "    \n",
    "    # weight of data above\n",
    "    p_of_data_above = len(data_above) / total_data_points\n",
    "    \n",
    "    overall_entropy = (p_of_data_below * calculate_entropy(data_below))+(p_of_data_above * calculate_entropy(data_above))\n",
    "    \n",
    "    return overall_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6695247011436225"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_overall_entropy(data_below, data_above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_splits = get_potential_splits(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(data, potential_splits):\n",
    "    \n",
    "    '''Figure out where the best split is for given data'''\n",
    "    \n",
    "    # set entropy to abritrary high number\n",
    "    overall_entropy = 500\n",
    "    \n",
    "    # for each dictionary key (0,1,2,3)\n",
    "    for column_index in potential_splits:\n",
    "        \n",
    "        # for each value within that key\n",
    "        for value in potential_splits[column_index]:\n",
    "            \n",
    "            # split the data \n",
    "            data_below, data_above = split_data(train_data, split_col=column_index, split_val=value)\n",
    "            \n",
    "            # calculate the entropy\n",
    "            current_overall_entropy = calculate_overall_entropy(data_below, data_above)\n",
    "\n",
    "            if current_overall_entropy < overall_entropy:\n",
    "                overall_entropy = current_overall_entropy\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "    \n",
    "    \n",
    "    \n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 2.45)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_best_split(train_data, potential_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must be a recursive function\n",
    "def decision_tree(df, counter=0, min_samples=2, max_depth=5):\n",
    "    if counter == 0:\n",
    "        global COLUMN_HEADERS\n",
    "        COLUMN_HEADERS = df.columns\n",
    "        data = df.values \n",
    "    else:\n",
    "        data = df\n",
    "    \n",
    "    # base case\n",
    "    if (purity(data)) or (len(data) < min_samples) or (counter == max_depth):\n",
    "        classification = classify(data)\n",
    "        return classification\n",
    "    \n",
    "    # if data not pure\n",
    "    else:\n",
    "        # increment counter\n",
    "        counter += 1\n",
    "        # recursion\n",
    "        potential_splits = get_potential_splits(data)\n",
    "        # Question: is our petal width < or > 0.8?\n",
    "    \n",
    "        split_col, split_val = find_best_split(data, potential_splits)\n",
    "        \n",
    "        data_below, data_above = split_data(data, split_col, split_val)\n",
    "        \n",
    "        feature_name = COLUMN_HEADERS[split_col]\n",
    "        question = \"{} <= {}\".format(feature_name, split_val)\n",
    "        subtree = {question: []}\n",
    "        \n",
    "        yes_answer = decision_tree(data_below, counter, min_samples, max_depth) \n",
    "        no_answer = decision_tree(data_above, counter, min_samples, max_depth)\n",
    "        \n",
    "        if yes_answer == no_answer:\n",
    "            subtree = yes_answer\n",
    "        else:\n",
    "        \n",
    "            subtree[question].append(yes_answer)\n",
    "            subtree[question].append(no_answer)\n",
    "        \n",
    "        return subtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(125,)\n",
      "(84,)\n",
      "{'PetalLengthCm <= 2.45': ['Iris-setosa',\n",
      "                           {'PetalLengthCm <= 3.25': ['Iris-versicolor',\n",
      "                                                      'Iris-virginica']}]}\n"
     ]
    }
   ],
   "source": [
    "tree = decision_tree(train, max_depth=2)\n",
    "pprint.pprint(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PetalLengthCm <= 2.45': ['Iris-setosa',\n",
       "  {'PetalLengthCm <= 3.25': ['Iris-versicolor', 'Iris-virginica']}]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_example(example, tree):\n",
    "    \n",
    "    # find the current question\n",
    "    question = list(tree.keys())[0]\n",
    "    # split it into the feature and value\n",
    "    feature_name, operator, value = question.split()\n",
    "    \n",
    "    # our tree is made up on subtrees\n",
    "    if example[feature_name] <= float(value):\n",
    "        # yes_answer = class \"Iris-setosa\"\n",
    "        answer = tree[question][0]\n",
    "    else:\n",
    "        # no answer = subtree\n",
    "        answer = tree[question][1]\n",
    "    \n",
    "    if not isinstance(answer, dict):\n",
    "            # return class\n",
    "        return answer\n",
    "    else:\n",
    "        # classify subtree\n",
    "        return classify_example(example, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'example' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-cd10a31cb312>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassify_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'example' is not defined"
     ]
    }
   ],
   "source": [
    "classify_example(example, tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(df, tree):\n",
    "    \n",
    "    # new column for our predictions\n",
    "    df['predictions'] = df.apply(classify_example, axis=1, args=(tree,))\n",
    "    #calculate how acc\n",
    "    df['correct_predictions'] = df.predictions == df.Species\n",
    "    \n",
    "    accuracy = df['correct_predictions'].mean()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_accuracy(train, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.iloc[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if percentages work \n",
    "train, test = train_test_split(df, 0.20)\n",
    "tree = decision_tree(train, max_depth=5)\n",
    "acc = calculate_accuracy(test, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
